---
title: "forelesningoppsummering"
format: pdf
editor: visual
---

## Utdanning på en skole hvem vet

```{r}
rm(list=ls()) 
library(tidyverse)
library(car)
load(url("http://www.principlesofeconometrics.com/poe5/data/rdata/star5_small.rdata"))

 data<-star5_small
 rm(star5_small)
```

```{r}
summary(data)
```

```{r}
mean(data$mathscore)

median(data$mathscore)

# Brukes basically bare for å kvadreres for å finne standardavviket
var(data$mathscore)

# Standardavviket tilsier at tallene er 48.5 over eller under gjennomsnittet
sd(data$mathscore)
```

```{r}
data <- na.omit(data)
# Kovariansen sier om hvordan forhold variablene har mellom seg
# Variablene beveger seg i samme retning da tallet er positivt
# 0 er ikke noe forhold, negativt er at de beveger seg vekk fra hverandre
cov(data$mathscore, data$tchexper)
```

```{r}
# Korrelasjonskoeffisienten måler både retning og grad av samvariasjon (mellom -1 og 1)
# 0.5-0.7 er moderat, over 0.7 er sterk
cor(data$mathscore, data$tchexper)
```

```{r}
# Viser korrelasjonskoeffisienten til alle variablene
cor(data)
```

```{r}
# Standardfeil er standardavviket til gjennomsnittet
# SE_M = Standardavviket / kvadratroten til n
# Dette betyr at på gjennomsnitt er vår data så langt ifra gjennomsnittet til populasjonen
# Dette kommer an på hvor "stort" tallet er, siden mathscore går til 626 i øverste verdi kan man "anta" at dette er et lavt tall
# Hadde mathscore gått til 27, kan man si at på gjennomsnitt er vår data langt ifra
sd(data$mathscore)/sqrt(nrow(data))
```

```{r}
# Standardfeil til korrelasjonskoeffisienten
sqrt(1-cor(data$mathscore, data$tchexper)^2)/sqrt(nrow(data)-2)

# Korrelasjonskoeffisienten
cor(data$mathscore, data$tchexper)^2
```

Konfidensintervall

Vanligsvis for oss 95%

Hvis vi har et estimat som er likt 10, og et konfidensnivå på 05% vil det være alle verdier mellom 9.5 og 10.5

Vi kan da anta at det er 95% sjanse for at den ordentlige verdien er mellom disse to verdiene et sted.

Gir kun mening å lage hvis vi har en faktisk test å evaluere

Hypotesetesting (t-test)

$$t = \frac{observert gjennomsnitt - nullhypotese} {estimert standardavvik til gjennomsnitt}$$

```{r}
t.test(readscore ~ small, data = data)

```

```{r}
t.test(readscore ~ small, alternative = "greater", data= data)
```

```{r}
t.test(readscore ~ small, alternative = "less", data= data)
```

```{r}
# Enkel lineær regresjon
# y = b * x + a
# a og b kalles for regresjonskoeffisienter
# Vi har avhengig variabel som vi ønsker å utforske yi
# Uavhengige variabelen er den som vi bruker den å forklare den avhengige xi
```

```{r}
reg <- data %>%
  lm(formula =totalscore ~tchexper)

summary(reg)
```

```{r}
data %>%
  ggplot(aes(x=tchexper, y=totalscore))+
  geom_point()+
  geom_smooth(se=FALSE, method="lm")
```

```{r}
# Hva må være sant? Gjennomsnittet til redisualene er 0 for alle fitted (estimerte( verdier))
# Visuell undersøkelse:
data %>%
  ggplot(aes(fitted(reg), y = residuals(reg)))+
  geom_point()+
  geom_smooth()+
  geom_hline(yintercept = 0)
```

```{r}
# Sjekker om redisualene er normalfordelt
shapiro.test(residuals(reg))

# Shapiro- test: nullhypotesen er at residualene er normalfordelt

# Vårt resultat: residualene er ikke normalfordelt, det er et brudd siden p-verdien er under 0.5


```

```{r}
# Normalitet: Q-Q plot
# Sjekker vår fodelinger opp mot en hypotetisk konstruert normalfordeling. Avvik fra linjen langs midten peker mot brudd

data %>%
  ggplot()+
  geom_qq(aes(sample = rstandard(reg)))+
  geom_abline(color = "red")
```

Homoskedastisitet

Hva må være sant? Residualene har lik varians for alle fitted verdier

```{r}
# Breusch-Pagan test, fra pakken car
# Har en p-verdi på 0.91 som ikke impliserer et brudd
ncvTest(reg)
```

```{r}
data %>%
  ggplot(aes(fitted(reg), sqrt(abs(rstandard(reg)))))+
  geom_point()
```

```{r}
#Visuell undersøkelse av homoskedastisitet
# Er linjen primært sett rett er antakelsen ikke brutt
# Det vil si at det er homoskedastisk, og ikke heteroskedastisk
# Kan også være et checkmark ish for å vise et brudd
data %>%
  ggplot(aes(fitted(reg), sqrt(abs(rstandard(reg)))))+
  geom_point()+
  geom_smooth(method ="loess")
```

Multippel regresjon

```{r}
# Viser alle variabler med .
mreg <- data %>%
  lm(formula = totalscore ~ .)

summary(mreg)
```

```{r}
mreg <- data %>%
  lm(formula = totalscore ~ aide + regular + tchexper)

summary(mreg)
```

Ny antakelse for multippel regresjon

Men den har en ny som er kollinearitet som er en korrelasjon mellom to eller flere av de uavhengige variablene.

```{r}
# Vi kan sjekke om det er kollinearitet ved bruk av korrelasjonsmatrisen fra tidligere
cor(data)
```

```{r}
# Men vi bruker heller en VIF-test, kommer fra pakken car
# fanger opp kollinearitet mellom par av variabler og grupper av variabler, og gir en enkel verdi
# Denne error betyr at det er perfekt kollinearitet
mreg2 <- data %>%
  lm(formula = totalscore ~ .)
vif(mreg2)
```

```{r}
# R mener det er for godt til å være sant siden man har med "perfekte" korrelerte varibler
mreg2 <- data %>%
  lm(formula = totalscore ~ aide + mathscore + readscore + regular + tchexper)
vif(mreg2)
```

```{r}
mreg2 <- data %>%
  lm(formula = totalscore ~ aide + mathscore + regular + tchexper)
summary(mreg2)
```

```{r}
mreg2 <- data %>%
  lm(formula = totalscore ~ aide + readscore + regular + tchexper)
summary(mreg2)
```
